{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3588d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "785415b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/22 19:54:00 WARN Utils: Your hostname, dengine resolves to a loopback address: 127.0.1.1; using 192.168.1.221 instead (on interface ens18)\n",
      "23/02/22 19:54:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/22 19:54:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51fdb3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('data/raw/green/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "408b73f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|VendorID|lpep_pickup_datetime|lpep_dropoff_datetime|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|ehail_fee|improvement_surcharge|total_amount|payment_type|trip_type|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|       2| 2021-01-01 00:15:56|  2021-01-01 00:19:52|                 N|         1|          43|         151|              1|         1.01|        5.5|  0.5|    0.5|         0|           0|     null|                  0.3|         6.8|           2|        1|                   0|\n",
      "|       2| 2021-01-01 00:25:59|  2021-01-01 00:34:44|                 N|         1|         166|         239|              1|         2.53|         10|  0.5|    0.5|      2.81|           0|     null|                  0.3|       16.86|           1|        1|                2.75|\n",
      "|       2| 2021-01-01 00:45:57|  2021-01-01 00:51:55|                 N|         1|          41|          42|              1|         1.12|          6|  0.5|    0.5|         1|           0|     null|                  0.3|         8.3|           1|        1|                   0|\n",
      "|       2| 2020-12-31 23:57:51|  2021-01-01 00:04:56|                 N|         1|         168|          75|              1|         1.99|          8|  0.5|    0.5|         0|           0|     null|                  0.3|         9.3|           2|        1|                   0|\n",
      "|       2| 2021-01-01 00:16:36|  2021-01-01 00:16:40|                 N|         2|         265|         265|              3|          .00|        -52|    0|   -0.5|         0|           0|     null|                 -0.3|       -52.8|           3|        1|                   0|\n",
      "|       2| 2021-01-01 00:16:36|  2021-01-01 00:16:40|                 N|         2|         265|         265|              3|          .00|         52|    0|    0.5|         0|           0|     null|                  0.3|        52.8|           2|        1|                   0|\n",
      "|       2| 2021-01-01 00:19:14|  2021-01-01 00:19:21|                 N|         5|         265|         265|              1|          .00|        180|    0|      0|     36.06|           0|     null|                  0.3|      216.36|           1|        2|                   0|\n",
      "|       2| 2021-01-01 00:26:31|  2021-01-01 00:28:50|                 N|         1|          75|          75|              6|          .45|        3.5|  0.5|    0.5|      0.96|           0|     null|                  0.3|        5.76|           1|        1|                   0|\n",
      "|       2| 2021-01-01 00:57:46|  2021-01-01 00:57:57|                 N|         1|         225|         225|              1|          .00|        2.5|  0.5|    0.5|         0|           0|     null|                  0.3|         3.8|           2|        1|                   0|\n",
      "|       2| 2021-01-01 00:58:32|  2021-01-01 01:32:34|                 N|         1|         225|         265|              1|        12.19|         38|  0.5|    0.5|      2.75|           0|     null|                  0.3|       42.05|           1|        1|                   0|\n",
      "|       2| 2021-01-01 00:31:14|  2021-01-01 00:55:07|                 N|         1|         244|         244|              2|         3.39|         18|  0.5|    0.5|         0|           0|     null|                  0.3|        19.3|           2|        1|                   0|\n",
      "|       2| 2021-01-01 00:08:50|  2021-01-01 00:21:56|                 N|         1|          75|         213|              1|         6.69|       19.5|  0.5|    0.5|         0|           0|     null|                  0.3|        20.8|           2|        1|                   0|\n",
      "|       2| 2021-01-01 00:35:13|  2021-01-01 00:44:44|                 N|         1|          74|         238|              1|         2.34|         10|  0.5|    0.5|         0|           0|     null|                  0.3|       14.05|           1|        1|                2.75|\n",
      "|       2| 2021-01-01 00:39:57|  2021-01-01 00:55:25|                 N|         1|          74|          60|              1|         5.48|         18|  0.5|    0.5|         0|           0|     null|                  0.3|        19.3|           2|        1|                   0|\n",
      "|       1| 2021-01-01 00:51:27|  2021-01-01 00:57:20|                 N|         1|          42|          41|              2|          .90|          6|  0.5|    0.5|         0|           0|     null|                  0.3|         7.3|           1|        1|                   0|\n",
      "|       2| 2021-01-01 00:29:05|  2021-01-01 00:29:07|                 N|         5|          42|         264|              1|          .00|         10|    0|      0|      2.06|           0|     null|                  0.3|       12.36|           1|        2|                   0|\n",
      "|       2| 2021-01-01 00:32:07|  2021-01-01 00:42:54|                 N|         1|          74|         116|              1|         2.08|        9.5|  0.5|    0.5|      2.16|           0|     null|                  0.3|       12.96|           1|        1|                   0|\n",
      "|       2| 2021-01-01 00:49:59|  2021-01-01 01:05:01|                 N|         1|         116|         143|              1|         4.64|       16.5|  0.5|    0.5|      5.14|           0|     null|                  0.3|       25.69|           1|        1|                2.75|\n",
      "|       2| 2021-01-01 00:07:20|  2021-01-01 00:12:01|                 N|         1|          75|          42|              1|         1.68|        6.5|  0.5|    0.5|         0|           0|     null|                  0.3|         7.8|           2|        1|                   0|\n",
      "|       2| 2021-01-01 00:25:54|  2021-01-01 00:28:20|                 N|         1|          74|          75|              1|          .68|          4|  0.5|    0.5|         0|           0|     null|                  0.3|         5.3|           2|        1|                   0|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "188d1feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: string (nullable = true)\n",
      " |-- lpep_pickup_datetime: string (nullable = true)\n",
      " |-- lpep_dropoff_datetime: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- passenger_count: string (nullable = true)\n",
      " |-- trip_distance: string (nullable = true)\n",
      " |-- fare_amount: string (nullable = true)\n",
      " |-- extra: string (nullable = true)\n",
      " |-- mta_tax: string (nullable = true)\n",
      " |-- tip_amount: string (nullable = true)\n",
      " |-- tolls_amount: string (nullable = true)\n",
      " |-- ehail_fee: string (nullable = true)\n",
      " |-- improvement_surcharge: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- trip_type: string (nullable = true)\n",
      " |-- congestion_surcharge: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e67108d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70bcc6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_pd = pd.read_csv('data/raw/green/2021/01/green_tripdata_2021_01.csv.gz', nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91c5ab3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', LongType(), True), StructField('lpep_pickup_datetime', StringType(), True), StructField('lpep_dropoff_datetime', StringType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('RatecodeID', LongType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('passenger_count', LongType(), True), StructField('trip_distance', DoubleType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('ehail_fee', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('payment_type', LongType(), True), StructField('trip_type', LongType(), True), StructField('congestion_surcharge', DoubleType(), True)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_green_pd).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d5d1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8de35a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_schema = types.StructType([\n",
    "    types.StructField('VendorID', types.IntegerType(), True),\n",
    "    types.StructField('lpep_pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('lpep_dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('store_and_fwd_flag', types.StringType(), True),\n",
    "    types.StructField('RatecodeID', types.IntegerType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('passenger_count', types.IntegerType(), True),\n",
    "    types.StructField('trip_distance', types.DoubleType(), True),\n",
    "    types.StructField('fare_amount', types.DoubleType(), True),\n",
    "    types.StructField('extra', types.DoubleType(), True),\n",
    "    types.StructField('mta_tax', types.DoubleType(), True),\n",
    "    types.StructField('tip_amount', types.DoubleType(), True),\n",
    "    types.StructField('tolls_amount', types.DoubleType(), True),\n",
    "    types.StructField('ehail_fee', types.DoubleType(), True),\n",
    "    types.StructField('improvement_surcharge', types.DoubleType(), True),\n",
    "    types.StructField('total_amount', types.DoubleType(), True),\n",
    "    types.StructField('payment_type', types.IntegerType(), True),\n",
    "    types.StructField('trip_type', types.IntegerType(), True),\n",
    "    types.StructField('congestion_surcharge', types.DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f46667b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(green_schema) \\\n",
    "    .csv('data/raw/green/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d579eecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- trip_type: integer (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3aeeb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow_pd = pd.read_csv('data/raw/yellow/2021/01/yellow_tripdata_2021_01.csv.gz', nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b275563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', LongType(), True), StructField('tpep_pickup_datetime', StringType(), True), StructField('tpep_dropoff_datetime', StringType(), True), StructField('passenger_count', LongType(), True), StructField('trip_distance', DoubleType(), True), StructField('RatecodeID', LongType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('payment_type', LongType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_yellow_pd).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53b83167",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_schema = types.StructType([\n",
    "    types.StructField('VendorID', types.IntegerType(), True),\n",
    "    types.StructField('tpep_pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('tpep_dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('passenger_count', types.IntegerType(), True),\n",
    "    types.StructField('trip_distance', types.DoubleType(), True),\n",
    "    types.StructField('RatecodeID', types.IntegerType(), True),\n",
    "    types.StructField('store_and_fwd_flag', types.StringType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('payment_type', types.IntegerType(), True),\n",
    "    types.StructField('fare_amount', types.DoubleType(), True),\n",
    "    types.StructField('extra', types.DoubleType(), True),\n",
    "    types.StructField('mta_tax', types.DoubleType(), True),\n",
    "    types.StructField('tip_amount', types.DoubleType(), True),\n",
    "    types.StructField('tolls_amount', types.DoubleType(), True),\n",
    "    types.StructField('improvement_surcharge', types.DoubleType(), True),\n",
    "    types.StructField('total_amount', types.DoubleType(), True),\n",
    "    types.StructField('congestion_surcharge', types.DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38b5ca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(yellow_schema) \\\n",
    "    .csv('data/raw/yellow/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65dd470b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/1\n",
      "processing data for 2021/2\n",
      "processing data for 2021/3\n",
      "processing data for 2021/4\n",
      "processing data for 2021/5\n",
      "processing data for 2021/6\n",
      "processing data for 2021/7\n",
      "processing data for 2021/8\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "Path does not exist: file:/home/udengine/git/data-engineering-zoomcamp/week_5_batch_processing/code/data/raw/green/2021/08",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6329/3842167177.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'data/pq/green/{year}/{month:02d}/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdf_green\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgreen_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: file:/home/udengine/git/data-engineering-zoomcamp/week_5_batch_processing/code/data/raw/green/2021/08"
     ]
    }
   ],
   "source": [
    "year = 2021\n",
    "for month in range(1, 13):\n",
    "    print(f'processing data for {year}/{month}')\n",
    "    input_path = f'data/raw/green/{year}/{month:02d}/'\n",
    "    output_path = f'data/pq/green/{year}/{month:02d}/'    \n",
    "    \n",
    "    df_green = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .schema(green_schema) \\\n",
    "        .csv(input_path)\n",
    "\n",
    "    df_green \\\n",
    "        .repartition(4) \\\n",
    "        .write.parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a20118fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 80:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "Path does not exist: file:/home/udengine/git/data-engineering-zoomcamp/week_5_batch_processing/code/data/raw/yellow/2021/08",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6329/932746463.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'data/pq/yellow/{year}/{month:02d}/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdf_yellow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myellow_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: file:/home/udengine/git/data-engineering-zoomcamp/week_5_batch_processing/code/data/raw/yellow/2021/08"
     ]
    }
   ],
   "source": [
    "year = 2021\n",
    "for month in range(1, 13):\n",
    "    print(f'processing data for {year}/{month}')\n",
    "    input_path = f'data/raw/yellow/{year}/{month:02d}/'\n",
    "    output_path = f'data/pq/yellow/{year}/{month:02d}/'    \n",
    "    \n",
    "    df_yellow = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .schema(yellow_schema) \\\n",
    "        .csv(input_path)\n",
    "\n",
    "    df_yellow \\\n",
    "        .repartition(4) \\\n",
    "        .write.parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfaea8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "year = 2020\n",
    "for month in range(1, 13):\n",
    "    print(f'processing data for {year}/{month}')\n",
    "    input_path = f'data/raw/yellow/{year}/{month:02d}/'\n",
    "    output_path = f'data/pq/yellow/{year}/{month:02d}/'    \n",
    "    \n",
    "    df_yellow = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .schema(yellow_schema) \\\n",
    "        .csv(input_path)\n",
    "\n",
    "    df_yellow \\\n",
    "        .repartition(4) \\\n",
    "        .write.parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85ee875f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001f�\b\b{��b\u0000\u0003yellow_tripdata_2020-08.csv\u0000��ۮ-Kr%��7��P\u001f0ς_㲟�E��\u0016\u0004H�y\"\u0012��\u0012�\"� �Z����{���9c\u0013�d2\u00173c��p77\u001b6l���_�������o��������������������������/�\u001f���ۿ�����������_����������?��ﯿ��?_�������_�鯯���\u001f����׿^������������������w���忿�\u001f�������/��������������_������\u001f����__��/�_�\u0017|�_�Ͽ��_^�����������~�.���o������������\u001f�G�������������\u0007����\u001f�\u001f���]/�\u001f�����_򫤒�H�\u001f)���~����g����+�r�)���x�����*����W}��'��O}5�_����KY�}�������������ܶ�\u0017������L��zt�?���R~�f�����ͷF��G�������d\u001f\\��ןm�(�6|�~^�~�����^��M޺���y�]�_�X~�ʯt�\u001a����r��\r",
      "���V��_��_p�A;ퟄ+�s\u001c",
      "����;��n�����F��W�/��������j�=]{�z\u001fx�u�\\\u001f2�(�׵\u0003��r�j�\u001f�j�%��7UX�<\u0016��� �zt����\\�w���\u00056y�\u000fZ�E;�#�<-����7�\u0006�7���l��^ks��V�7-\u001b���gdu�h�_����X:�Exf\r\n",
      "o�z��+�~������s���\u001e",
      "�K�%�����\u0003��U�<<�T�c�D�'��M�ٮ_`#A�x�2o�koá��\\�N�9�xx���k�\u0005��]��\u0017Ћ�I��\u000e{�z����bZ���aן�\u0010` �\u001c",
      "\u001b���\u0016��I��:�m�������+��_����i�\\�]���%�|��\u000f��w��\u0017F��g�\u000f\r\n",
      "O��w���k�ue�g�z\u001d",
      "��g'|����;-\u000b",
      ",�P����)Ĭ���\u001e",
      "�\u0007���=�Lυg���\u0017i�E'�C�¢\u0013\u0002���O�\u001c",
      "\u0001����6.�$�������g;�`�ذ�������ጾ\u000e\u001b\u0019Ktp�C���\b_vǋ!ӣ�q��\u0002�\\�76\u001b;�\u001b\u0002�y����\u0004�\u0006^�\u0010O^��7�q�̜��\r",
      "��l��g\u0011\u001e",
      "��p�����8����U̝��g\u0010B\u0012��&1p�]���spV�\\��qm<LT���w��ܜm��D\"�+z�O�0\u000e�\r\n",
      "ʓa�\u0015H\u001a�#�>�ZU\u0013��E����h��x���-�~0\u00171!���j�V����c�\u0004��J��A����Z�h�wp�(4%��}�+����ʦ2�R�d���87%k�)�s}��n��J��\u0015��ֺ�VL_�i�\u001d",
      "}�#�V��8�kC���\u001e",
      "W\"�-p�k3Q�\u001e",
      "aԸ��\u000b",
      "^\u00073�tV�ٙ���ͫ����\r",
      "�ۿm�Mu�\u0004\u000b",
      "��(\u0018 ��^���ӯ*\"xz7Wb�X��Ε������[�If\u0014��˙���\u0016�\u0016@�O��.���\u0016Ltouyg|2�l#�i?�,I�!�q\u001f�\u001a,�98X/4�n�\u001bl;��gg}v\u000b",
      "�\r",
      ";�\u0004�\u0013�\u0016l�}$f�����-Ǫ\u0004��λ����\u0006�,�\u0002�������\u0014�`\u0007�6@�\u0002Q\u0015J�&ۻ��<�7�5��$�g\u000b",
      "6�\u000euޒ(lT<u]�Lo]ds����\u00136zX�����\u0017\u0006���-�8�Xl��2b`����S���P\b�)��j�\u0002!�*�����{��\u0004\t_Y�'��\u001d",
      "���'\u0017\u000e��K�2��}\u0014PWe\u0012��%aj�.W�M~�o�t���g��K�����\u0005T�����\u0001ŷ�\u001d",
      "��e�Ǝ����\u001b��!0k�{\u0002�\u0005+\u0006���\u0014F\u0016s���qݤ\u001b�z�\t���\u0007��ؕ'�5K��}��x�_��9Z7�=��^\u001f��&���tv6\r",
      "��=\\�P�e��`\r",
      "\u000eO�X��b�`�>��>+��)���\u000e�q���W\u0000�n�\u0013_|�Ө�\u001e",
      "����\u0018�l\f",
      "\u000f4�\r",
      "v����p~\u0000\u0019�+­?�w�\r\n",
      "/[�$J��\u001a?��\u0010^�1\u001fM�*�\u001e",
      "��l�b�~�5�e�]�\u0013J\u001bx�u��\u0016�v�����/�d����-��'˙�Mh\"�W2]��*��\\\u0013�i=*��5�8�\u0010�0\t\u0010�?�U�ˢ\\7��\u0011��\u001f2Z�\r",
      "�:��c\r\n",
      "�p�\u0015\t��츸%�=4\u0019�|�+���������9p_��F�m���\u000e����`Oh\u0006\u0001G\u0007>����3;���\u0007\u0004�*E5�m�Ktw��dK��t&�UN:�G���u\u0001\u001e",
      "]\u0017:�Pǆ��Ҏ\u001e",
      "\b�7\u0000f�+��Yg�\u0004[�\u0011D�7F\u0018���+��w\\��k=0dן�e7�~�\u0018T�\u001f�7{�_e\u000fd��]d��\u0007�\u0015\u0003\r\n",
      "hS.��\\�95Ε�Q�\u0004O�\u0005��B!�)f��K=�_x%���u=M]y\u001d",
      "�6�H\r",
      "�?�z\u0006�%�\tΝ�8\b��z\u0000\u001f����\u001e",
      "�v\u0010Ֆ�H\u0016�4�Rg\u0002Ѣ��p��ksRka*Z�B{�:\\٪\u0001\u001d",
      "*\\\u0012��ԅ��M\u001f�#{�\b�������~!�S$�\u0001�!cl����\"\u0013�\u001c",
      "����ŧ�Y�f������!�\u0005E�y�녟|�lTB9[$x2tWVt�J6\u0011��9��G���[P�.x\u000f�\u001c",
      "�K�_Xv4\u00016�j�d{|��q=\u00004Yw�u'\u0014jR4)�2f:�LG�\u0016�MD���\u0012����n%�����{�G��5\f",
      "f@���]��qzv\u0005\u0003��S���1l\r",
      "A\u0003a���\r",
      "�:�A��`eL��.\u00030���\u00191��7��*\r",
      "����\u000b",
      "�iӵ����e�(\u0004\u0001�;�m�\u0015����ݍ\u0010�(��y�I�JX�)@�ӏ銋q�� �\u0004kn|3\u0003\u0014\u00041�Ŏ\u0015�s�\u0002��_�~�\u0010\u0012ms�Ԋ��q�V-�������\u0001կ��h�5��h�������E��3�\r",
      "��Ǟ6\r",
      "�\u0012/�\u001e",
      "�)��k�է\u001b?8�דR_\u000ej�ԍ��탪��?�)�(@��7lvM\u0003�\u0006\r\n",
      "�k���r\u0014��*�Jj_~�2z��䖋\u0003\u001b[pf��h�Y$�z�i�\r",
      "yJ�Ǟ��!�\u0000�`���`��\u0013l\r\n",
      "���\b#�����\tm�yd\u0014�\u0011A��\u001e",
      "���q�y��N�ŕa�eq^E���G�a�W�\f",
      "}��\u0000��\u0011WnS0�m��9�\r\n",
      "+ޓ�\u000b",
      "\u0014j��j4�����\u000f\f",
      "/�&�R\u001b6Na�Q\u0002\u00154���O�Ѐ�θ\u0006t\u0012���8lA�8[�H��M9�����\u001c",
      "VV�@\bmfT顭%ۛt�ڜ\u0013r��Հ\u000e��w��&���\u001f-47��~�u�,\u001f�n��\u0006��\u0006��P\u001e",
      "Lb�Đ�����^\u0014��M�Z!Z�\u0011@���\u0015?�Uit\u0001�����_W��w�9���x탢�\u0019\u0018�Nk�\u0011\u00188R�\u001d",
      "�3�x��hW��\u0006�I��d*��^^A\\z����s\u001as\t7��\\\\\u001f�����G�`|��\u0019�\u0002�J�Ӿw��\u001e",
      "\u0000^N�ӈ�&o}����$�`���k�\u0004���3�\u0014\u001d",
      "�gS)?��:5в6�<^�z�_{��&��¯;�\u00159�/\u001au\u0015\u000f\u000b",
      "S]���^ە���}�S<B�uP\u001b��h*6(EJ��k��+\"0�K���u��zp�=��v���G�h��0�>\t�٦\u001b����$S�\u0013��aN\"�=\u001d",
      "\u001fh\f",
      "��NK�Iz�J��\u0000���?�1t�'ף�N\u0007hY�\u0012n\u0012�n��Z���V��ǋ����/��E\u000er3\u0013�'5mHT�<�\"\u001d",
      "&,$V�\u000b",
      "\u000f!Nb���q�a��]kb����� �\u0014$�|���T(�\f",
      "8ؙf��Θ���R&��kq�\u0007�kJ��\u0017�;��R�$\u001d",
      "�?�\f",
      "�\u0005)fj��\u0002�\u0002�K��\u0015�a�C�Q{��\u001e",
      "��䅸͛�Spӟ��&�\u0006�ɘ-o�&���؞K�s�`=�M\\��F�eU@)#��^k�����7ī���{���H��+�q�Eܡ��㉂3\u0003��R}�\u0004V��rm�4S� ��?�:x�G����Q����\u00133��Ϲ��V���F����\f",
      "չ�6He�\b�׳+/�rSB�?���\f",
      "+��\u001e",
      "���{���� �\u000e��ca�\u0001q�д���\tv�\u0002��\bz�H5'\u001b�f\u0003sU\u0014ż~\u000f�S\u0013\u000b",
      "D��\u0016b�С0�<�=@��#�&8m\u0000�\u0016�\u0011\f",
      "�\u000b",
      "��4\u0011��\u0012�(5]�\u00158��f���a��\\7�6x�Z/Q\u001b\u0000��{p�[\u0000m�\u000f\bŀ8�A\u000f�\t�Ա\u0011Gs5\f",
      "!�md_\u0015k#���F��\u00123 ��9��wU��z�T)t�\u001e",
      "�G���\u001c",
      "����\u0011�D\u001c",
      "�H�.�\u000e�JŌ �D��b��RC�h:\u000b",
      "���Q,\\;����XW:G+\r",
      "DO�h�d��\u001e",
      "(�j�\f",
      "=\u001d",
      "�i΄B�Y%�lM�?�\u0019��W\u000ewH��0Q�{q�*\u0018�\u0019S�߀лi�f8�\u0000�\r",
      "�\b�\t��9�˙���pZ\f",
      "&羮u\u001e",
      "�JyA\u0017g�u\u001d",
      "�\u001e",
      "�i�&��_����\u0019�W�3�:����j�ץ�}k~V�Q��3&2��\u001f�\u0010�������G�\u0011\f",
      "�=yz\u0019�Ü�\u0005��d\u001f\f",
      "��\t�ϵ\u0017���\b�M��>�~�³߲�\u0005P\u0016\"x��g\u0007\r",
      "�|@\u0002�xX�H��~,f$����6\u001d",
      "SI��\u00143�\u0019��k�W�\u0013��nϚϹ�6\b\u001c",
      " �eʀ]ibΰ�\"\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 data/raw/yellow/2020/08/yellow_tripdata_2020_08.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77c053b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'data/raw/2020': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/raw/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eaf15a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/udengine/git/data-engineering-zoomcamp/week_5_batch_processing/code'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50411f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = pd.read_csv('data/raw/yellow/2020/10/yellow_tripdata_2020_10.csv.gz', nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71fcdec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', LongType(), True), StructField('tpep_pickup_datetime', StringType(), True), StructField('tpep_dropoff_datetime', StringType(), True), StructField('passenger_count', LongType(), True), StructField('trip_distance', DoubleType(), True), StructField('RatecodeID', LongType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('payment_type', LongType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_review).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eba831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
